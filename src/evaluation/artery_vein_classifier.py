import click
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import joblib
import os
import glob
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, \
    roc_auc_score, f1_score, accuracy_score, roc_curve
from tqdm import tqdm
from src.utils.susi import ExperimentResults
from src import settings
from src.utils.gather_pa_spectra_from_dataset import calculate_mean_spectrum
from sklearn.calibration import CalibratedClassifierCV

here = Path(__file__)
np.random.seed(141)


def load_data(data_base_root: str, gan_cinn_root: str, unit_root: str, target: str = "val"):

    if target == "val":
        test_real_data_root = os.path.join(data_base_root, "real_images", "validation")
    elif target == "test":
        test_real_data_root = os.path.join(data_base_root, "real_images", "test")
    else:
        raise KeyError("Choose either 'test' or 'val' as target data set!")

    val_real_data_root = os.path.join(data_base_root, "real_images", "validation")
    train_real_data_root = os.path.join(data_base_root, "real_images", "training")
    sim_root = os.path.join(data_base_root, "good_simulations", "training")

    test_real_data = glob.glob(os.path.join(test_real_data_root, "*.npz"))
    val_real_data = glob.glob(os.path.join(val_real_data_root, "*.npz"))
    train_real_data = glob.glob(os.path.join(train_real_data_root, "*.npz"))
    sim_data = glob.glob(os.path.join(sim_root, "*.npz"))
    gan_cinn_data = glob.glob(os.path.join(gan_cinn_root, "*.npz"))
    unit_data = glob.glob(os.path.join(unit_root, "*.npz"))

    test_real_spectra = calculate_mean_spectrum(test_real_data)
    val_real_spectra = calculate_mean_spectrum(val_real_data)
    train_real_spectra = calculate_mean_spectrum(train_real_data)
    sim_spectra = calculate_mean_spectrum(sim_data[:len(test_real_data)])
    gan_cinn_spectra = calculate_mean_spectrum(gan_cinn_data[:len(test_real_data)])
    unit_spectra = calculate_mean_spectrum(unit_data[:len(test_real_data)])

    datasets = {
        "test_real_spectra": test_real_spectra,
        "val_real_spectra": val_real_spectra,
        "train_real_spectra": train_real_spectra,
        "sim_spectra": sim_spectra,
        "gan_cinn_spectra": gan_cinn_spectra,
        "unit_spectra": unit_spectra,
    }

    for key, value in datasets.items():
        labels = np.concatenate([
            np.ones(len(value["artery_spectra_all"])),
            np.zeros(len(value["vein_spectra_all"]))
        ])

        spectra = np.concatenate([
            value["artery_spectra_all"],
            value["vein_spectra_all"]
        ])

        indices = np.arange(len(labels))
        np.random.shuffle(indices)

        spectra, labels = spectra[indices], labels[indices]

        datasets[key] = (spectra, labels)

    results = dict(train=dict(x_real=datasets["train_real_spectra"][0], y_real=datasets["train_real_spectra"][1],
                              x_simulated=datasets["sim_spectra"][0], y_simulated=datasets["sim_spectra"][1],
                              x_cINN=datasets["gan_cinn_spectra"][0], y_cINN=datasets["gan_cinn_spectra"][1],
                              x_UNIT=datasets["unit_spectra"][0], y_UNIT=datasets["unit_spectra"][1]),
                   test=dict(x_real=datasets["test_real_spectra"][0], y_real=datasets["test_real_spectra"][1]))

    return results


def get_model(x: np.ndarray, y: np.ndarray, **kwargs):
    model = RandomForestClassifier(**kwargs)
    model.fit(x, y)
    return model


def eval_classification(data_base_root: str, gan_cinn_root: str, unit_root: str, target: str = "val"):
    stages = [
        'real',  # train model on real train set sub sampled to have same size as test set
        'simulated',  # train model on synthetic test set generated by sampling wavelengths
        'UNIT',  # train model on synthetic test set adapted to real domain via UNIT
        'cINN',  # train model on synthetic test set adapted to real domain via INNs
    ]
    mapping = {0: "vein", 1: "artery"}
    labels = [int(k) for k in mapping]
    names = [mapping[k] for k in labels]
    data = load_data(data_base_root, gan_cinn_root, unit_root, target)
    per_class_metrics = False
    metrics = ExperimentResults()
    for stage in tqdm(stages, desc="iterating stages"):
        train_data = data.get('train').get(f'x_{stage}')
        train_labels = data.get('train').get(f'y_{stage}')
        model = get_model(train_data, train_labels, n_jobs=-1, n_estimators=100)
        # compute score on test set of real data
        test_data = data.get('test').get('x_real')
        test_labels = data.get('test').get('y_real')

        model = CalibratedClassifierCV(model)
        model.fit(train_data, train_labels)
        y_cal_proba = model.predict_proba(test_data)
        y_cal_pred = model.predict(test_data)

        report = classification_report(test_labels, y_cal_pred, target_names=names, labels=labels, output_dict=True)

        if per_class_metrics:
            conf_matrix = confusion_matrix(test_labels, y_cal_pred)
            per_class_accuracies = list()

            for n_idx, name in enumerate(names):
                true_negatives = np.sum(np.delete(np.delete(conf_matrix, n_idx, axis=0), n_idx, axis=1))
                true_positives = conf_matrix[n_idx, n_idx]
                per_class_accuracies.append((true_positives + true_negatives) / np.sum(conf_matrix))

            per_class_auroc = roc_auc_score(y_true=test_labels, y_score=y_cal_proba[:, 1], multi_class="ovr", average=None)
            per_class_f1 = f1_score(y_true=test_labels, y_pred=y_cal_pred, average=None)
            metrics.append(name='per_class_accuracy', value=per_class_accuracies)
            metrics.append(name='per_class_auroc', value=per_class_auroc)
            metrics.append(name='per_class_f1', value=per_class_f1)
            metrics.append(name='data', value=[stage for _ in names])
            metrics.append(name='organ', value=names)

            print(f'\nf1 score {stage}: {per_class_f1}')
            print(f"balanced_accuracy_score {stage} {per_class_accuracies}")
            print(f"roc_auc_score {stage} {per_class_auroc}")
        else:
            balanced_accuracy = balanced_accuracy_score(y_true=test_labels, y_pred=y_cal_pred)
            accuracy = accuracy_score(y_true=test_labels, y_pred=y_cal_pred)
            roc_auc = roc_auc_score(y_true=test_labels, y_score=y_cal_proba[:, 1])
            f1 = f1_score(y_true=test_labels, y_pred=y_cal_pred, average="weighted")
            metrics.append(name='balanced_accuracy', value=float(balanced_accuracy))
            metrics.append(name='roc_auc', value=float(roc_auc))
            metrics.append(name='f1', value=float(f1))
            metrics.append(name='model', value=stage)

            print("#### With calibration ####")
            print(f"balanced_accuracy_score {stage} {balanced_accuracy}")
            print(f"roc_auc_score {stage} {roc_auc}")
            print(f'f1 score {stage}: {f1}')

        results = pd.DataFrame(report)
        save_dir_path = settings.results_dir / 'rf_pa'
        if not os.path.exists(save_dir_path):
            os.makedirs(save_dir_path, exist_ok=True)
        results.to_csv(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_report_{stage}.csv', index=True)

        matrix = confusion_matrix(test_labels, y_cal_pred, labels=labels, normalize='pred')
        np.savez(str(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_matrix_{stage}.npz'), matrix=matrix, labels=labels)
        np.save(str(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_train_x_{stage}.npy'), train_data)
        np.save(str(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_train_y_{stage}.npy'), train_labels)
        np.save(str(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_test_x_{stage}.npy'), test_data)
        np.save(str(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_test_y_{stage}.npy'), test_labels)
        np.save(str(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_test_y_pred_{stage}.npy'), y_cal_pred)
        np.save(str(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_test_y_proba_{stage}.npy'), y_cal_pred)
        # np.savez(str(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_matrix_{stage}.npz'), matrix=matrix, labels=labels)
        joblib.dump(model, str(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_{stage}.joblib'))
    # exit()
    metrics = metrics.get_df()
    metrics.to_csv(settings.results_dir / 'rf_pa' / f'rf_pa_classifier_metrics.csv', index=True)


@click.command()
@click.option('--rf_pa', default=True, is_flag=True, help="evaluate random forest classifier")
@click.option('--target', type=str, default='val', help="target data set used to compute classification results")
@click.option('--data_base_root', type=str, help="path to the database")
@click.option('--gan_cinn_root', type=str, help="path to the data generated by the gan_cinn")
@click.option('--unit_root', type=str, help="path to the data generated by the unit")
def main(rf_pa: bool, data_base_root: str, gan_cinn_root: str, unit_root: str, target: str = "val"):
    if rf_pa:
        eval_classification(data_base_root, gan_cinn_root, unit_root, target)


if __name__ == '__main__':
    main()
