experiment_name: gan_cinn

high_res_conv: 2
middle_res_conv: 1
low_res_conv: 1
downsampling_levels: 5
downsampling_type: haar
clamping: 1.
epochs: 300
seed: 42

n_blocks: 20
n_conditional_blocks: 15
actnorm: .7
n_reflections: 0
n_hidden: 256
ndim_x: 16


batch_size: 2
num_workers: 16
shuffle: 1
learning_rate: 0.001
spectral_consistency: 0
sc_weight: 0.1
adversarial_training: 1
gan_weight: 1
ml_weight: 1
recon_criterion: mse        # mse or abs
noise_aug: True
noise_aug_level: 0.05
normalization: standardize    # min_max, standardize or none
instant_downsampling: False
weight_decay: 0.001           # weight decay
beta1: 0.4                    # Adam parameter
beta2: 0.999
condition: segmentation       # segmentation, domain, both
label_noise: False
label_noise_level: 0.2

data:
  data_set_name: real_sim     # real_sim, sim or mnist_usps
  data_dir_a: test_dir_a
  data_dir_b: test_dir_b
  used_channels: 16          # int as index of list [700, 855, 10] or list of int as indices, e.g. [0, 3, 6, 15]
  log: False                 # indicate if data have been taken logarithmic
  n_classes: 7

dis:
  dim: 64                     # number of filters in the bottommost layer
  normalization: none                  # normalization layer [none/bn/in/ln]
  activation: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 3                  # number of layers in D
  gan_type: lsgan             # GAN loss [lsgan/nsgan]
  num_scales: 3               # number of scales
  padding_type: replicate
  dropout: True
  dropout_p: 0.2
